{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tttx_gDu3wB0"
      },
      "source": [
        "loading required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qpaw7JX88k7",
        "outputId": "9df2b444-5788-4214-f9ad-b471ceea4789"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Current Working Directory: /content/drive/MyDrive/diagnosis-assistant\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: langchain-ollama in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.2.3)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.3.17)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.1)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in /usr/local/lib/python3.11/dist-packages (from langchain-ollama->-r requirements.txt (line 2)) (0.3.35)\n",
            "Requirement already satisfied: ollama<1,>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from langchain-ollama->-r requirements.txt (line 2)) (0.4.7)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.18 in /usr/local/lib/python3.11/dist-packages (from langchain-community->-r requirements.txt (line 3)) (0.3.18)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community->-r requirements.txt (line 3)) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community->-r requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community->-r requirements.txt (line 3)) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community->-r requirements.txt (line 3)) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community->-r requirements.txt (line 3)) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community->-r requirements.txt (line 3)) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community->-r requirements.txt (line 3)) (2.7.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community->-r requirements.txt (line 3)) (0.3.8)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community->-r requirements.txt (line 3)) (0.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 3)) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 3)) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 3)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 3)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 3)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 3)) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 3)) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 3)) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.18->langchain-community->-r requirements.txt (line 3)) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.18->langchain-community->-r requirements.txt (line 3)) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama->-r requirements.txt (line 2)) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama->-r requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama->-r requirements.txt (line 2)) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community->-r requirements.txt (line 3)) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community->-r requirements.txt (line 3)) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community->-r requirements.txt (line 3)) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community->-r requirements.txt (line 3)) (0.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community->-r requirements.txt (line 3)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community->-r requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community->-r requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community->-r requirements.txt (line 3)) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community->-r requirements.txt (line 3)) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community->-r requirements.txt (line 3)) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community->-r requirements.txt (line 3)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community->-r requirements.txt (line 3)) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain-ollama->-r requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community->-r requirements.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community->-r requirements.txt (line 3)) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 3)) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community->-r requirements.txt (line 3)) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/diagnosis-assistant')\n",
        "\n",
        "# Verify current directory\n",
        "print(\"Current Working Directory:\", os.getcwd())\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1SMefrT3wB7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', 5000)\n",
        "from dotenv import load_dotenv\n",
        "import json\n",
        "from src.utils import (\n",
        "    load_preprocess_data,\n",
        "    run_prediction,\n",
        "    extract_disease_names,\n",
        "    select_case_components_based_on_id)\n",
        "load_dotenv()\n",
        "from prompts import single_shot_disease_only_prompt,with_reasons_prompt,compare_others_prompt,self_refinement_prompt,compare_others_prompt_without_mine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb07TT5A3wB-"
      },
      "source": [
        "importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJWs_JIc3wB_",
        "outputId": "71d6b13f-b220-4bfb-c7e5-a3a04763e6e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "number of total cases are 1500\n",
            "\n",
            "each case have the following fields ['id', 'clinical_case_uid', 'language', 'clinical_department', 'principal_diagnosis', 'preliminary_diagnosis', 'diagnostic_basis', 'differential_diagnosis', 'treatment_plan', 'clinical_case_summary', 'imageological_examination', 'laboratory_examination', 'pathological_examination', 'therapeutic_principle']\n",
            "\n",
            "number of departments available are 24\n",
            "\n",
            " all the departments available are\n",
            "clinical_department\n",
            "orthopedics department                              100\n",
            "anus and intestine surgical department              100\n",
            "hepatobiliary and pancreas surgical department       99\n",
            "urinary surgical department                          90\n",
            "otolaryngology head and neck surgical department     80\n",
            "neurology department                                 80\n",
            "endocrinology department                             80\n",
            "gynecology department                                80\n",
            "neurosurgery department                              70\n",
            "thoracic surgical department                         70\n",
            "respiratory medicine department                      70\n",
            "cardiac surgical department                          70\n",
            "gastroenterology department                          70\n",
            "pediatrics department                                60\n",
            "nephrology department                                60\n",
            "gastrointestinal surgical department                 60\n",
            "thyroid surgical department                          50\n",
            "hernia surgical department                           40\n",
            "cardiovascular medicine department                   40\n",
            "vascular surgical department                         40\n",
            "breast surgical department                           40\n",
            "hematology department                                30\n",
            "obstetrics department                                20\n",
            "Gastroenterology                                      1\n",
            "Name: count, dtype: int64\n",
            "1181\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-90c56bdfe831>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['differential_diagnosis'] = filtered_df['differential_diagnosis'] + filtered_df['principal_diagnosis'].apply(lambda x: [x] if x else [])\n"
          ]
        }
      ],
      "source": [
        "filePath=\"clinicallab/data_en.json\"\n",
        "df=load_preprocess_data(filePath)\n",
        "df['differential_diagnosis'] = df['differential_diagnosis'].apply(extract_disease_names)\n",
        "filtered_df = df[df['differential_diagnosis'].apply(lambda x: len(x) > 1)]\n",
        "filtered_df['differential_diagnosis'] = filtered_df['differential_diagnosis'] + filtered_df['principal_diagnosis'].apply(lambda x: [x] if x else [])\n",
        "df=filtered_df\n",
        "print(len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11faclmr3wCA"
      },
      "outputs": [],
      "source": [
        "# 729/3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1fonLHB3wCA"
      },
      "source": [
        "filtering the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vysOVu503wCB"
      },
      "outputs": [],
      "source": [
        "# from src.utils import (\n",
        "#     run_prediction,\n",
        "# )\n",
        "# from prompts import single_shot_disease_only_prompt,with_reasons_prompt,compare_others_prompt,self_refinement_prompt\n",
        "# type=\"with_reasons\"\n",
        "# prompt=with_reasons_prompt\n",
        "# type=\"single_shot\"\n",
        "# prompt=single_shot_disease_only_prompt\n",
        "# # type=\"open_ended\"\n",
        "# # # prompt=open_ended__top4_prompt#\n",
        "# run_prediction(df,prompt,departments,models=models,type=type,skip=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfEQK4P93wCC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import os\n",
        "# import json\n",
        "# from src.utils import evaluate_department_results\n",
        "# types=[\"single_shot\",\"with_reasons\",\"check_others_input\"]\n",
        "\n",
        "# for type in types:\n",
        "#     folder=os.path.join(\"results\",type)\n",
        "#     print(\"type is\",type)\n",
        "#     all_files=os.listdir(folder)\n",
        "#     all_results={}\n",
        "#     for file in all_files:\n",
        "#         department_name=file.split(\"_\")[0]\n",
        "#         print(department_name)\n",
        "#         if type in file:\n",
        "#             file_path=os.path.join(folder,file)\n",
        "#             department_name=file.split(\"_\")[0]\n",
        "#             with open(file_path, \"r\") as file:\n",
        "#                 data = json.load(file)\n",
        "#                 results=evaluate_department_results(data)\n",
        "#             all_results[department_name]=results\n",
        "\n",
        "#     with open(f\"results/analysis/{type}.json\", \"w\") as outfile:\n",
        "#         json.dump(all_results, outfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiKwIDpK37Bj",
        "outputId": "8e9044c9-15fc-4632-d5e7-7a5a8dbfb103"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.91.82)] [Connecting to security.ub\u001b[0m\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.81)] [\u001b[0m\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,526 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,911 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,230 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,610 kB]\n",
            "Fetched 8,533 kB in 3s (3,303 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "25 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "pciutils is already the newest version (1:3.7.0-6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n",
            ">>> Cleaning up old version at /usr/local/lib/ollama\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "############################################################################################# 100.0%\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            ">>> NVIDIA GPU installed.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "!sudo apt update\n",
        "!sudo apt install -y pciutils\n",
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aLWMXzBX5N18"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "def run_ollama_serve():\n",
        "  subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "thread = threading.Thread(target=run_ollama_serve)\n",
        "thread.start()\n",
        "time.sleep(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B_eVzLo5Piq",
        "outputId": "80b7d138-100f-4e0f-da13-0af8109ba87e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling 667b0c1932bc... 100% ▕▏ 4.9 GB                         \n",
            "pulling 948af2743fc7... 100% ▕▏ 1.5 KB                         \n",
            "pulling 0ba8f0e314b4... 100% ▕▏  12 KB                         \n",
            "pulling 56bb8bd477a5... 100% ▕▏   96 B                         \n",
            "pulling 455f34728c9b... 100% ▕▏  487 B                         \n",
            "verifying sha256 digest \n",
            "writing manifest \n",
            "success \u001b[?25h\n"
          ]
        }
      ],
      "source": [
        "!ollama pull llama3.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "t4FDqcIA3wCD"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate\n",
        "from langchain_ollama.llms import OllamaLLM\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jMzSUAou3wCE"
      },
      "outputs": [],
      "source": [
        "required_fields=[ \"Patient basic information\",\n",
        "                 \"Chief complaint\",\n",
        "                 \"Medical history\",\n",
        "                 \"Physical examination\",\n",
        "                 \"Laboratory examination\",\n",
        "                 \"Imageological examination\",\n",
        "                 \"Auxillary examination\",\n",
        "                 \"Pathological examination\"\n",
        "\n",
        "]\n",
        "departments=[\"nephrology department\",\n",
        "            \"gynecology department\",\n",
        "            \"endocrinology department\",\n",
        "            \"neurology department\",\n",
        "             \"pediatrics department\",\n",
        "             \"cardiac surgical department\",\n",
        "             \"gastrointestinal surgical department\",\n",
        "             \"respiratory medicine department\",\n",
        "             \"gastroenterology department\",\n",
        "             \"urinary surgical department\",\n",
        "             \"hepatobiliary and pancreas surgical department\",\n",
        "             \"hematology department\"\n",
        "            ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FFjQUYMo3wCF"
      },
      "outputs": [],
      "source": [
        "def get_diagnosis_by_other_models_by_id(id,department_results,models):\n",
        "    all_diagnosis=[]\n",
        "    for model in models:\n",
        "        diagnosis=department_results[id][\"predictions\"][model]\n",
        "        diagnosis= diagnosis.replace(\"\\n\", \"\")\n",
        "        diagnosis= diagnosis.replace(\"```json\", \"\")\n",
        "        diagnosis= diagnosis.replace(\"```\", \"\")\n",
        "        all_diagnosis.append(diagnosis)\n",
        "    return all_diagnosis\n",
        "\n",
        "def compare_others_ollama(prompt,medical_history, modelname, diseases, department,doctor_diagnosis=[]):\n",
        "    model = OllamaLLM(model=modelname,temperature=0.1,num_predict=1500,num_ctx=4096)#1500\n",
        "\n",
        "    system_template = prompt\n",
        "\n",
        "    system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
        "    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt])\n",
        "    chain = chat_prompt | model\n",
        "    if len(doctor_diagnosis)==1:\n",
        "        results=chain.invoke({\"department\": department,\n",
        "                            \"diseases\": diseases,\n",
        "                            \"medical_history\":json.dumps(medical_history),\n",
        "                            \"diagnosis\":doctor_diagnosis[0]})\n",
        "        return results\n",
        "    elif len(doctor_diagnosis)==2:\n",
        "        results=chain.invoke({\"department\": department,\n",
        "                            \"diseases\": diseases,\n",
        "                            \"medical_history\":json.dumps(medical_history),\n",
        "                            \"doctor_1_diagnosis\":doctor_diagnosis[0],\n",
        "                            \"doctor_2_diagnosis\":doctor_diagnosis[1]})\n",
        "        return results\n",
        "    elif len(doctor_diagnosis)==3:\n",
        "        results=chain.invoke({\"department\": department,\n",
        "                            \"diseases\": diseases,\n",
        "                            \"medical_history\":json.dumps(medical_history),\n",
        "                            \"doctor_1_diagnosis\":doctor_diagnosis[0],\n",
        "                            \"doctor_2_diagnosis\":doctor_diagnosis[1],\n",
        "                            \"doctor_3_diagnosis\":doctor_diagnosis[2]})\n",
        "        return results\n",
        "\n",
        "\n",
        "\n",
        "def compare_others_gpt(prompt,medical_history, model, diseases, department,doctor_diagnosis=[]):\n",
        "    chat = ChatOpenAI(model_name=model, temperature=0.1,max_tokens=1500)\n",
        "    system_template = prompt\n",
        "    system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
        "\n",
        "    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt])\n",
        "\n",
        "    # Format the messages\n",
        "    messages = chat_prompt.format_prompt(\n",
        "        department=department,\n",
        "        diseases=diseases,\n",
        "        medical_history=json.dumps(medical_history),\n",
        "        doctor_1_diagnosis=doctor_diagnosis[0],\n",
        "        doctor_2_diagnosis=doctor_diagnosis[1],\n",
        "        doctor_3_diagnosis=doctor_diagnosis[2],\n",
        "\n",
        "    ).to_messages()\n",
        "    response = chat(messages)\n",
        "    return response.content\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQmdF6QT3wCG"
      },
      "source": [
        "### Check others including mine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jC94dh83wCG"
      },
      "outputs": [],
      "source": [
        "\n",
        "all_models= [\"gpt-4o\",\"llama3.1\",\"gemma2\"]\n",
        "all_models_to_check=[\"gpt-4o\",\"llama3.1\",\"gemma2\"]\n",
        "type=\"check_others_input\"\n",
        "prompt_type=compare_others_prompt\n",
        "for department in departments:\n",
        "    print(department)\n",
        "    results={}\n",
        "    with open(f\"results4/with_reasons/{department}_with_reasons.json\", \"r\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    department_results=data\n",
        "    ids=list(department_results.keys())\n",
        "    print(ids)\n",
        "    for case_id in ids:\n",
        "        print(case_id)\n",
        "        case_details={}\n",
        "        principal_diagnosis,differential_diagnosis,filtered_clinical_case_dict=select_case_components_based_on_id(df,int(case_id),required_fields)\n",
        "        doctor_diagnosis=get_diagnosis_by_other_models_by_id(case_id,department_results,all_models)\n",
        "        case_details[\"original\"]={\"main-diagnosis\":principal_diagnosis,\"differential_diagnosis\":differential_diagnosis}\n",
        "        case_details[\"predictions\"]={}\n",
        "        for model in all_models_to_check:\n",
        "            if \"gpt\" in model:\n",
        "                output=compare_others_gpt(prompt_type,filtered_clinical_case_dict,model,differential_diagnosis,department,doctor_diagnosis)\n",
        "            else:\n",
        "                output=compare_others_ollama(prompt_type,filtered_clinical_case_dict,model,differential_diagnosis,department,doctor_diagnosis)\n",
        "            case_details[\"predictions\"][model]=output\n",
        "        results[str(case_id)]=case_details\n",
        "\n",
        "    with open(f\"results/{type}/{department}_{type}.json\", \"w\") as outfile:\n",
        "        json.dump(results, outfile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqMYjqwl3wCH"
      },
      "source": [
        "### Self refinement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6Ih2EZM3wCH",
        "outputId": "edb50f21-a681-409e-ab54-71e496eda4d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nephrology department\n",
            "['1142', '1145', '1148', '1151', '1154', '1157', '1160', '1172', '1175', '1178', '1181', '1184', '1187', '1190', '1193', '1196', '1199']\n",
            "1142\n",
            "1145\n",
            "1148\n",
            "1151\n",
            "1154\n",
            "1157\n",
            "1160\n",
            "1172\n",
            "1175\n",
            "1178\n",
            "1181\n",
            "1184\n",
            "1187\n",
            "1190\n",
            "1193\n",
            "1196\n",
            "1199\n",
            "gynecology department\n",
            "['272', '275', '279', '284', '288', '292', '296', '303', '307', '310', '313', '316', '321', '324', '327', '330', '338', '341', '344', '347', '350']\n",
            "272\n",
            "275\n",
            "279\n",
            "284\n",
            "288\n",
            "292\n",
            "296\n"
          ]
        }
      ],
      "source": [
        "all_models= [\"llama3.1\"]\n",
        "all_models_to_check=[\"llama3.1\"]\n",
        "type=\"self_refinement\"\n",
        "prompt_type=self_refinement_prompt\n",
        "for department in departments:\n",
        "    print(department)\n",
        "    results={}\n",
        "    with open(f\"results4/with_reasons/{department}_with_reasons.json\", \"r\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    department_results=data\n",
        "    ids=list(department_results.keys())\n",
        "    print(ids)\n",
        "    for case_id in ids:\n",
        "        print(case_id)\n",
        "        case_details={}\n",
        "        principal_diagnosis,differential_diagnosis,filtered_clinical_case_dict=select_case_components_based_on_id(df,int(case_id),required_fields)\n",
        "        doctor_diagnosis=get_diagnosis_by_other_models_by_id(case_id,department_results,all_models)\n",
        "        case_details[\"original\"]={\"main-diagnosis\":principal_diagnosis,\"differential_diagnosis\":differential_diagnosis}\n",
        "        case_details[\"predictions\"]={}\n",
        "        for i,model in enumerate(all_models_to_check):\n",
        "            doctor_diagnosis=[doctor_diagnosis[i]]\n",
        "            if \"gpt\" in model:\n",
        "                output=compare_others_gpt(prompt_type,filtered_clinical_case_dict,model,differential_diagnosis,department,doctor_diagnosis)\n",
        "            else:\n",
        "                output=compare_others_ollama(prompt_type,filtered_clinical_case_dict,model,differential_diagnosis,department,doctor_diagnosis)\n",
        "            case_details[\"predictions\"][model]=output\n",
        "        results[str(case_id)]=case_details\n",
        "    path = f\"results5/{type}/{model}/{department}_{type}.json\"\n",
        "    folder_path = os.path.dirname(path)\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "    with open(path, \"w\") as outfile:\n",
        "      json.dump(results, outfile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT58HWpv3wCH"
      },
      "source": [
        "### Check others without mine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cb6ANtx3wCI"
      },
      "outputs": [],
      "source": [
        "all_models= [\"gpt-4o\",\"llama3.1\",\"gemma2\"]\n",
        "all_models_to_check=[\"gpt-4o\",\"llama3.1\",\"gemma2\"]\n",
        "type=\"check_others_input_without_mine\"\n",
        "prompt_type=compare_others_prompt_without_mine\n",
        "for department in departments:\n",
        "    print(department)\n",
        "    results={}\n",
        "    with open(f\"results4/with_reasons/{department}_with_reasons.json\", \"r\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    department_results=data\n",
        "    ids=list(department_results.keys())\n",
        "    print(ids)\n",
        "    for case_id in ids:\n",
        "        print(case_id)\n",
        "        case_details={}\n",
        "        principal_diagnosis,differential_diagnosis,filtered_clinical_case_dict=select_case_components_based_on_id(df,int(case_id),required_fields)\n",
        "        doctor_diagnosis=get_diagnosis_by_other_models_by_id(case_id,department_results,all_models)\n",
        "        case_details[\"original\"]={\"main-diagnosis\":principal_diagnosis,\"differential_diagnosis\":differential_diagnosis}\n",
        "        case_details[\"predictions\"]={}\n",
        "        for i,model in enumerate(all_models_to_check):\n",
        "            doctor_diagnosis1=doctor_diagnosis[:]\n",
        "            if model==\"gpt-4o\":\n",
        "              continue\n",
        "            del doctor_diagnosis1[i]\n",
        "\n",
        "            if \"gpt\" in model:\n",
        "                output=compare_others_gpt(prompt_type,filtered_clinical_case_dict,model,differential_diagnosis,department,doctor_diagnosis1)\n",
        "            else:\n",
        "                output=compare_others_ollama(prompt_type,filtered_clinical_case_dict,model,differential_diagnosis,department,doctor_diagnosis1)\n",
        "            case_details[\"predictions\"][model]=output\n",
        "        results[str(case_id)]=case_details\n",
        "\n",
        "    path = f\"results5/{type}/{model}/{department}_{type}.json\"\n",
        "    folder_path = os.path.dirname(path)\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "    with open(path, \"w\") as outfile:\n",
        "      json.dump(results, outfile)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
