{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### loading setup to run ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiKwIDpK37Bj",
        "outputId": "8e9044c9-15fc-4632-d5e7-7a5a8dbfb103"
      },
      "outputs": [],
      "source": [
        "!sudo apt update\n",
        "!sudo apt install -y pciutils\n",
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLWMXzBX5N18"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "def run_ollama_serve():\n",
        "  subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "thread = threading.Thread(target=run_ollama_serve)\n",
        "thread.start()\n",
        "time.sleep(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B_eVzLo5Piq",
        "outputId": "80b7d138-100f-4e0f-da13-0af8109ba87e"
      },
      "outputs": [],
      "source": [
        "!ollama pull llama3.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tttx_gDu3wB0"
      },
      "source": [
        "### loading google zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qpaw7JX88k7",
        "outputId": "9df2b444-5788-4214-f9ad-b471ceea4789"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/diagnosis-assistant')\n",
        "print(\"Current Working Directory:\", os.getcwd())\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### loading required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', 5000)\n",
        "from dotenv import load_dotenv\n",
        "import json\n",
        "from src.utils import (\n",
        "    load_preprocess_data,\n",
        "    run_prediction,\n",
        "    extract_disease_names,\n",
        "    select_case_components_based_on_id,\n",
        "    unzip_flatten_top_level,\n",
        "    zip_folder)\n",
        "load_dotenv()\n",
        "from prompts import single_shot_disease_only_prompt,with_reasons_prompt,compare_others_prompt,self_refinement_prompt,compare_others_prompt_without_mine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb07TT5A3wB-"
      },
      "source": [
        "### importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jMzSUAou3wCE"
      },
      "outputs": [],
      "source": [
        "required_fields=[ \"Patient basic information\",\n",
        "                 \"Chief complaint\",\n",
        "                 \"Medical history\",\n",
        "                 \"Physical examination\",\n",
        "                 \"Laboratory examination\",\n",
        "                 \"Imageological examination\",\n",
        "                 \"Auxillary examination\",\n",
        "                 \"Pathological examination\"\n",
        "\n",
        "]\n",
        "departments=[\"nephrology department\",\n",
        "            \"gynecology department\",\n",
        "            \"endocrinology department\",\n",
        "            \"neurology department\",\n",
        "             \"pediatrics department\",\n",
        "             \"cardiac surgical department\",\n",
        "             \"gastrointestinal surgical department\",\n",
        "             \"respiratory medicine department\",\n",
        "             \"gastroenterology department\",\n",
        "             \"urinary surgical department\",\n",
        "             \"hepatobiliary and pancreas surgical department\",\n",
        "             \"hematology department\"\n",
        "            ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJWs_JIc3wB_",
        "outputId": "71d6b13f-b220-4bfb-c7e5-a3a04763e6e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "number of total cases are 1500\n",
            "\n",
            "each case have the following fields ['id', 'clinical_case_uid', 'language', 'clinical_department', 'principal_diagnosis', 'preliminary_diagnosis', 'diagnostic_basis', 'differential_diagnosis', 'treatment_plan', 'clinical_case_summary', 'imageological_examination', 'laboratory_examination', 'pathological_examination', 'therapeutic_principle']\n",
            "\n",
            "number of departments available are 24\n",
            "\n",
            " all the departments available are\n",
            "clinical_department\n",
            "orthopedics department                              100\n",
            "anus and intestine surgical department              100\n",
            "hepatobiliary and pancreas surgical department       99\n",
            "urinary surgical department                          90\n",
            "endocrinology department                             80\n",
            "gynecology department                                80\n",
            "otolaryngology head and neck surgical department     80\n",
            "neurology department                                 80\n",
            "thoracic surgical department                         70\n",
            "respiratory medicine department                      70\n",
            "gastroenterology department                          70\n",
            "neurosurgery department                              70\n",
            "cardiac surgical department                          70\n",
            "nephrology department                                60\n",
            "gastrointestinal surgical department                 60\n",
            "pediatrics department                                60\n",
            "thyroid surgical department                          50\n",
            "hernia surgical department                           40\n",
            "breast surgical department                           40\n",
            "cardiovascular medicine department                   40\n",
            "vascular surgical department                         40\n",
            "hematology department                                30\n",
            "obstetrics department                                20\n",
            "Gastroenterology                                      1\n",
            "Name: count, dtype: int64\n",
            "1181\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jzlco\\AppData\\Local\\Temp\\ipykernel_2072\\3614222219.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['differential_diagnosis'] = filtered_df['differential_diagnosis'] + filtered_df['principal_diagnosis'].apply(lambda x: [x] if x else [])\n"
          ]
        }
      ],
      "source": [
        "filePath=\"dataset/clinicallab/data_en.json\"\n",
        "df=load_preprocess_data(filePath)\n",
        "df['differential_diagnosis'] = df['differential_diagnosis'].apply(extract_disease_names)\n",
        "filtered_df = df[df['differential_diagnosis'].apply(lambda x: len(x) > 1)]\n",
        "filtered_df['differential_diagnosis'] = filtered_df['differential_diagnosis'] + filtered_df['principal_diagnosis'].apply(lambda x: [x] if x else [])\n",
        "df=filtered_df\n",
        "print(len(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### running prediction for single_shot,with_reasons and open_ended"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vysOVu503wCB"
      },
      "outputs": [],
      "source": [
        "# from src.utils import (\n",
        "#     run_prediction,\n",
        "# )\n",
        "# from prompts import single_shot_disease_only_prompt,with_reasons_prompt,compare_others_prompt,self_refinement_prompt\n",
        "# type=\"with_reasons\"\n",
        "# prompt=with_reasons_prompt\n",
        "# type=\"single_shot\"\n",
        "# prompt=single_shot_disease_only_prompt\n",
        "# # type=\"open_ended\"\n",
        "# # # prompt=open_ended__top4_prompt#\n",
        "# run_prediction(df,prompt,departments,models=models,type=type,skip=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### evaluate the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfEQK4P93wCC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import os\n",
        "# import json\n",
        "# from src.utils import evaluate_department_results\n",
        "# types=[\"single_shot\",\"with_reasons\",\"check_others_input\"]\n",
        "\n",
        "# for type in types:\n",
        "#     folder=os.path.join(\"results\",type)\n",
        "#     print(\"type is\",type)\n",
        "#     all_files=os.listdir(folder)\n",
        "#     all_results={}\n",
        "#     for file in all_files:\n",
        "#         department_name=file.split(\"_\")[0]\n",
        "#         print(department_name)\n",
        "#         if type in file:\n",
        "#             file_path=os.path.join(folder,file)\n",
        "#             department_name=file.split(\"_\")[0]\n",
        "#             with open(file_path, \"r\") as file:\n",
        "#                 data = json.load(file)\n",
        "#                 results=evaluate_department_results(data)\n",
        "#             all_results[department_name]=results\n",
        "\n",
        "#     with open(f\"results/analysis/{type}.json\", \"w\") as outfile:\n",
        "#         json.dump(all_results, outfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FFjQUYMo3wCF"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate\n",
        "from langchain_ollama.llms import OllamaLLM\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "def get_diagnosis_by_other_models_by_id(id,department_results,models):\n",
        "    all_diagnosis=[]\n",
        "    for model in models:\n",
        "        diagnosis=department_results[id][\"predictions\"][model]\n",
        "        diagnosis= diagnosis.replace(\"\\n\", \"\")\n",
        "        diagnosis= diagnosis.replace(\"```json\", \"\")\n",
        "        diagnosis= diagnosis.replace(\"```\", \"\")\n",
        "        all_diagnosis.append(diagnosis)\n",
        "    return all_diagnosis\n",
        "\n",
        "def compare_others_ollama(prompt,medical_history, modelname, diseases, department,doctor_diagnosis=[]):\n",
        "    model = OllamaLLM(model=modelname,temperature=0.1,num_predict=1500,num_ctx=4096)#1500\n",
        "\n",
        "    system_template = prompt\n",
        "\n",
        "    system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
        "    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt])\n",
        "    chain = chat_prompt | model\n",
        "    if len(doctor_diagnosis)==1:\n",
        "        results=chain.invoke({\"department\": department,\n",
        "                            \"diseases\": diseases,\n",
        "                            \"medical_history\":json.dumps(medical_history),\n",
        "                            \"diagnosis\":doctor_diagnosis[0]})\n",
        "        return results\n",
        "    elif len(doctor_diagnosis)==2:\n",
        "        results=chain.invoke({\"department\": department,\n",
        "                            \"diseases\": diseases,\n",
        "                            \"medical_history\":json.dumps(medical_history),\n",
        "                            \"doctor_1_diagnosis\":doctor_diagnosis[0],\n",
        "                            \"doctor_2_diagnosis\":doctor_diagnosis[1]})\n",
        "        return results\n",
        "    elif len(doctor_diagnosis)==3:\n",
        "        results=chain.invoke({\"department\": department,\n",
        "                            \"diseases\": diseases,\n",
        "                            \"medical_history\":json.dumps(medical_history),\n",
        "                            \"doctor_1_diagnosis\":doctor_diagnosis[0],\n",
        "                            \"doctor_2_diagnosis\":doctor_diagnosis[1],\n",
        "                            \"doctor_3_diagnosis\":doctor_diagnosis[2]})\n",
        "        return results\n",
        "\n",
        "\n",
        "\n",
        "def compare_others_gpt(prompt,medical_history, model, diseases, department,doctor_diagnosis=[]):\n",
        "    chat = ChatOpenAI(model_name=model, temperature=0.1,max_tokens=1500)\n",
        "    system_template = prompt\n",
        "    system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
        "\n",
        "    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt])\n",
        "    if len(doctor_diagnosis)==1:\n",
        "        messages = chat_prompt.format_prompt(\n",
        "            department=department,\n",
        "            diseases=diseases,\n",
        "            medical_history=json.dumps(medical_history),\n",
        "            diagnosis=doctor_diagnosis[0],\n",
        "\n",
        "        ).to_messages()\n",
        "    elif len(doctor_diagnosis)==2:\n",
        "        messages = chat_prompt.format_prompt(\n",
        "            department=department,\n",
        "            diseases=diseases,\n",
        "            medical_history=json.dumps(medical_history),\n",
        "            doctor_1_diagnosis=doctor_diagnosis[0],\n",
        "            doctor_2_diagnosis=doctor_diagnosis[1]\n",
        "\n",
        "        ).to_messages()\n",
        "    elif len(doctor_diagnosis)==3:\n",
        "        messages = chat_prompt.format_prompt(\n",
        "            department=department,\n",
        "            diseases=diseases,\n",
        "            medical_history=json.dumps(medical_history),\n",
        "            doctor_1_diagnosis=doctor_diagnosis[0],\n",
        "            doctor_2_diagnosis=doctor_diagnosis[1],\n",
        "            doctor_3_diagnosis=doctor_diagnosis[2],\n",
        "\n",
        "        ).to_messages()\n",
        "    response = chat(messages)\n",
        "    return response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQmdF6QT3wCG"
      },
      "source": [
        "### Check others including mine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jC94dh83wCG"
      },
      "outputs": [],
      "source": [
        "\n",
        "all_models= [\"gpt-4o\",\"llama3.1\",\"gemma2\"]\n",
        "all_models_to_check=[\"gpt-4o\",\"llama3.1\",\"gemma2\"]\n",
        "type=\"check_others_input\"\n",
        "prompt_type=compare_others_prompt\n",
        "for department in departments:\n",
        "    print(department)\n",
        "    results={}\n",
        "    with open(f\"results4/with_reasons/{department}_with_reasons.json\", \"r\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    department_results=data\n",
        "    ids=list(department_results.keys())\n",
        "    print(ids)\n",
        "    for case_id in ids:\n",
        "        print(case_id)\n",
        "        case_details={}\n",
        "        principal_diagnosis,differential_diagnosis,filtered_clinical_case_dict=select_case_components_based_on_id(df,int(case_id),required_fields)\n",
        "        doctor_diagnosis=get_diagnosis_by_other_models_by_id(case_id,department_results,all_models)\n",
        "        case_details[\"original\"]={\"main-diagnosis\":principal_diagnosis,\"differential_diagnosis\":differential_diagnosis}\n",
        "        case_details[\"predictions\"]={}\n",
        "        for model in all_models_to_check:\n",
        "            if \"gpt\" in model:\n",
        "                output=compare_others_gpt(prompt_type,filtered_clinical_case_dict,model,differential_diagnosis,department,doctor_diagnosis)\n",
        "            else:\n",
        "                output=compare_others_ollama(prompt_type,filtered_clinical_case_dict,model,differential_diagnosis,department,doctor_diagnosis)\n",
        "            case_details[\"predictions\"][model]=output\n",
        "        results[str(case_id)]=case_details\n",
        "\n",
        "    with open(f\"results/{type}/{department}_{type}.json\", \"w\") as outfile:\n",
        "        json.dump(results, outfile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqMYjqwl3wCH"
      },
      "source": [
        "### Self refinement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6Ih2EZM3wCH",
        "outputId": "edb50f21-a681-409e-ab54-71e496eda4d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nephrology department\n",
            "['1142', '1145', '1148', '1151', '1154', '1157', '1160', '1172', '1175', '1178', '1181', '1184', '1187', '1190', '1193', '1196', '1199']\n",
            "1142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jzlco\\AppData\\Local\\Temp\\ipykernel_2072\\832836857.py:48: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  chat = ChatOpenAI(model_name=model, temperature=0.1,max_tokens=1500)\n",
            "C:\\Users\\jzlco\\AppData\\Local\\Temp\\ipykernel_2072\\832836857.py:80: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = chat(messages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1145\n",
            "1148\n",
            "1151\n",
            "1154\n",
            "1157\n",
            "1160\n",
            "1172\n",
            "1175\n",
            "1178\n",
            "1181\n",
            "1184\n",
            "1187\n",
            "1190\n",
            "1193\n",
            "1196\n",
            "1199\n",
            "gynecology department\n",
            "['272', '275', '279', '284', '288', '292', '296', '303', '307', '310', '313', '316', '321', '324', '327', '330', '338', '341', '344', '347', '350']\n",
            "272\n",
            "275\n",
            "279\n",
            "284\n",
            "288\n",
            "292\n",
            "296\n",
            "303\n",
            "307\n",
            "310\n",
            "313\n",
            "316\n",
            "321\n",
            "324\n",
            "327\n",
            "330\n",
            "338\n",
            "341\n",
            "344\n",
            "347\n",
            "350\n",
            "endocrinology department\n",
            "['122', '125', '128', '131', '134', '138', '141', '144', '147', '150', '153', '156', '159', '162', '165', '168', '171', '174', '177', '180', '183', '187', '190', '193', '196', '199']\n",
            "122\n",
            "125\n",
            "128\n",
            "131\n",
            "134\n",
            "138\n",
            "141\n",
            "144\n",
            "147\n",
            "150\n",
            "153\n",
            "156\n",
            "159\n",
            "162\n",
            "165\n",
            "168\n",
            "171\n",
            "174\n",
            "177\n",
            "180\n",
            "183\n",
            "187\n",
            "190\n",
            "193\n",
            "196\n",
            "199\n",
            "neurology department\n",
            "['712', '715', '718', '722', '726', '729', '732', '735', '738', '741', '744', '747', '750', '753', '756', '759', '762', '765', '769', '772', '775', '778', '781', '784', '787', '790']\n",
            "712\n",
            "715\n",
            "718\n",
            "722\n",
            "726\n",
            "729\n",
            "732\n",
            "735\n",
            "738\n",
            "741\n",
            "744\n",
            "747\n",
            "750\n",
            "753\n",
            "756\n",
            "759\n",
            "762\n",
            "765\n",
            "769\n",
            "772\n",
            "775\n",
            "778\n",
            "781\n",
            "784\n",
            "787\n",
            "790\n",
            "pediatrics department\n",
            "['62', '66', '69', '72', '75', '79', '82', '85', '88', '91', '95', '98', '101', '104', '107', '110', '113', '116', '119']\n",
            "62\n",
            "66\n",
            "69\n",
            "72\n",
            "75\n",
            "79\n",
            "82\n",
            "85\n",
            "88\n",
            "91\n",
            "95\n",
            "98\n",
            "101\n",
            "104\n",
            "107\n",
            "110\n",
            "113\n",
            "116\n",
            "119\n",
            "cardiac surgical department\n",
            "['352', '355', '358', '361', '365', '370', '376', '381', '384', '389', '395', '401', '408']\n",
            "352\n",
            "355\n",
            "358\n",
            "361\n",
            "365\n",
            "370\n",
            "376\n",
            "381\n",
            "384\n",
            "389\n",
            "395\n",
            "401\n",
            "408\n",
            "gastrointestinal surgical department\n",
            "['1202', '1205', '1208', '1211', '1214', '1217', '1220', '1223', '1226', '1229', '1233', '1236', '1239', '1243', '1251', '1254', '1258']\n",
            "1202\n",
            "1205\n",
            "1208\n",
            "1211\n",
            "1214\n",
            "1217\n",
            "1220\n",
            "1223\n",
            "1226\n",
            "1229\n",
            "1233\n",
            "1236\n",
            "1239\n",
            "1243\n",
            "1251\n",
            "1254\n",
            "1258\n",
            "respiratory medicine department\n",
            "['202', '205', '208', '211', '214', '217', '220', '224', '227', '230', '233', '236', '239', '242', '247', '252', '255', '258', '261', '264', '267', '270']\n",
            "202\n",
            "205\n",
            "208\n",
            "211\n",
            "214\n",
            "217\n",
            "220\n",
            "224\n",
            "227\n",
            "230\n",
            "233\n",
            "236\n",
            "239\n",
            "242\n",
            "247\n",
            "252\n",
            "255\n",
            "258\n",
            "261\n",
            "264\n",
            "267\n",
            "270\n",
            "gastroenterology department\n",
            "['552', '555', '558', '561', '564', '567', '570', '573', '576', '579', '582', '585', '588', '591', '594', '597', '600', '603', '606', '609', '612', '615', '618']\n",
            "552\n",
            "555\n",
            "558\n",
            "561\n",
            "564\n",
            "567\n",
            "570\n",
            "573\n",
            "576\n",
            "579\n",
            "582\n",
            "585\n",
            "588\n",
            "591\n",
            "594\n",
            "597\n",
            "600\n",
            "603\n",
            "606\n",
            "609\n",
            "612\n",
            "615\n",
            "618\n",
            "urinary surgical department\n",
            "['462', '465', '468', '472', '475', '486', '492', '496', '499', '502', '505', '508', '511', '514', '518', '521', '525', '529', '533', '536', '539', '542', '545', '548']\n",
            "462\n",
            "465\n",
            "468\n",
            "472\n",
            "475\n",
            "486\n",
            "492\n",
            "496\n",
            "499\n",
            "502\n",
            "505\n",
            "508\n",
            "511\n",
            "514\n",
            "518\n",
            "521\n",
            "525\n",
            "529\n",
            "533\n",
            "536\n",
            "539\n",
            "542\n",
            "545\n",
            "548\n",
            "hepatobiliary and pancreas surgical department\n",
            "['1043', '1047', '1050', '1053', '1056', '1061', '1071', '1074', '1078', '1081', '1085', '1092', '1095', '1098', '1101', '1104', '1107', '1110', '1113', '1116', '1119', '1122', '1125', '1128', '1134', '1137', '1140']\n",
            "1043\n",
            "1047\n",
            "1050\n",
            "1053\n",
            "1056\n",
            "1061\n",
            "1071\n",
            "1074\n",
            "1078\n",
            "1081\n",
            "1085\n",
            "1092\n",
            "1095\n",
            "1098\n",
            "1101\n",
            "1104\n",
            "1107\n",
            "1110\n",
            "1113\n",
            "1116\n",
            "1119\n",
            "1122\n",
            "1125\n",
            "1128\n",
            "1134\n",
            "1137\n",
            "1140\n",
            "hematology department\n",
            "['1332', '1335', '1338', '1343', '1346', '1352', '1356', '1359']\n",
            "1332\n",
            "1335\n",
            "1338\n",
            "1343\n",
            "1346\n",
            "1352\n",
            "1356\n",
            "1359\n"
          ]
        }
      ],
      "source": [
        "all_models= [\"gpt-4o\"]\n",
        "all_models_to_check=[\"gpt-4o\"]\n",
        "type=\"self_refinement\"\n",
        "prompt_type=self_refinement_prompt\n",
        "for department in departments:\n",
        "    print(department)\n",
        "    results={}\n",
        "    with open(f\"results-all-models/with_reasons/{department}_with_reasons.json\", \"r\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    department_results=data\n",
        "    ids=list(department_results.keys())\n",
        "    print(ids)\n",
        "    for case_id in ids:\n",
        "        print(case_id)\n",
        "        case_details={}\n",
        "        principal_diagnosis,differential_diagnosis,filtered_clinical_case_dict=select_case_components_based_on_id(df,int(case_id),required_fields)\n",
        "        doctor_diagnosis=get_diagnosis_by_other_models_by_id(case_id,department_results,all_models)\n",
        "        case_details[\"original\"]={\"main-diagnosis\":principal_diagnosis,\"differential_diagnosis\":differential_diagnosis}\n",
        "        case_details[\"predictions\"]={}\n",
        "        for i,model in enumerate(all_models_to_check):\n",
        "            doctor_diagnosis=[doctor_diagnosis[i]]\n",
        "            if \"gpt\" in model:\n",
        "                output=compare_others_gpt(prompt_type,filtered_clinical_case_dict,model,differential_diagnosis,department,doctor_diagnosis)\n",
        "            else:\n",
        "                output=compare_others_ollama(prompt_type,filtered_clinical_case_dict,model,differential_diagnosis,department,doctor_diagnosis)\n",
        "            case_details[\"predictions\"][model]=output\n",
        "        results[str(case_id)]=case_details\n",
        "    path = f\"results-self-refinement/{type}/{model}/{department}_{type}.json\"\n",
        "    folder_path = os.path.dirname(path)\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "    with open(path, \"w\") as outfile:\n",
        "      json.dump(results, outfile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT58HWpv3wCH"
      },
      "source": [
        "### Check others without mine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cb6ANtx3wCI"
      },
      "outputs": [],
      "source": [
        "all_models= [\"gpt-4o\",\"llama3.1\",\"gemma2\"]\n",
        "all_models_to_check=[\"gpt-4o\",\"llama3.1\",\"gemma2\"]\n",
        "type=\"check_others_input_without_mine\"\n",
        "prompt_type=compare_others_prompt_without_mine\n",
        "for department in departments:\n",
        "    print(department)\n",
        "    results={}\n",
        "    with open(f\"results4/with_reasons/{department}_with_reasons.json\", \"r\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    department_results=data\n",
        "    ids=list(department_results.keys())\n",
        "    print(ids)\n",
        "    for case_id in ids:\n",
        "        print(case_id)\n",
        "        case_details={}\n",
        "        principal_diagnosis,differential_diagnosis,filtered_clinical_case_dict=select_case_components_based_on_id(df,int(case_id),required_fields)\n",
        "        doctor_diagnosis=get_diagnosis_by_other_models_by_id(case_id,department_results,all_models)\n",
        "        case_details[\"original\"]={\"main-diagnosis\":principal_diagnosis,\"differential_diagnosis\":differential_diagnosis}\n",
        "        case_details[\"predictions\"]={}\n",
        "        for i,model in enumerate(all_models_to_check):\n",
        "            doctor_diagnosis1=doctor_diagnosis[:]\n",
        "            if model==\"gpt-4o\":\n",
        "              continue\n",
        "            del doctor_diagnosis1[i]\n",
        "\n",
        "            if \"gpt\" in model:\n",
        "                output=compare_others_gpt(prompt_type,filtered_clinical_case_dict,model,differential_diagnosis,department,doctor_diagnosis1)\n",
        "            else:\n",
        "                output=compare_others_ollama(prompt_type,filtered_clinical_case_dict,model,differential_diagnosis,department,doctor_diagnosis1)\n",
        "            case_details[\"predictions\"][model]=output\n",
        "        results[str(case_id)]=case_details\n",
        "\n",
        "    path = f\"results5/{type}/{model}/{department}_{type}.json\"\n",
        "    folder_path = os.path.dirname(path)\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "    with open(path, \"w\") as outfile:\n",
        "      json.dump(results, outfile)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
