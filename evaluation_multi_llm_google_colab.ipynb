{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tttx_gDu3wB0"
      },
      "source": [
        "loading required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qpaw7JX88k7",
        "outputId": "9df2b444-5788-4214-f9ad-b471ceea4789"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/diagnosis-assistant')\n",
        "\n",
        "# Verify current directory\n",
        "print(\"Current Working Directory:\", os.getcwd())\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1SMefrT3wB7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', 5000)\n",
        "from dotenv import load_dotenv\n",
        "import json\n",
        "from src.utils import (\n",
        "    load_preprocess_data,\n",
        "    run_prediction,\n",
        "    extract_disease_names,\n",
        "    select_case_components_based_on_id)\n",
        "load_dotenv()\n",
        "from prompts import single_shot_disease_only_prompt,with_reasons_prompt,compare_others_prompt,self_refinement_prompt,compare_others_prompt_without_mine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb07TT5A3wB-"
      },
      "source": [
        "importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJWs_JIc3wB_",
        "outputId": "71d6b13f-b220-4bfb-c7e5-a3a04763e6e4"
      },
      "outputs": [],
      "source": [
        "filePath=\"clinicallab/data_en.json\"\n",
        "df=load_preprocess_data(filePath)\n",
        "df['differential_diagnosis'] = df['differential_diagnosis'].apply(extract_disease_names)\n",
        "filtered_df = df[df['differential_diagnosis'].apply(lambda x: len(x) > 1)]\n",
        "filtered_df['differential_diagnosis'] = filtered_df['differential_diagnosis'] + filtered_df['principal_diagnosis'].apply(lambda x: [x] if x else [])\n",
        "df=filtered_df\n",
        "print(len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11faclmr3wCA"
      },
      "outputs": [],
      "source": [
        "# 729/3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1fonLHB3wCA"
      },
      "source": [
        "filtering the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vysOVu503wCB"
      },
      "outputs": [],
      "source": [
        "# from src.utils import (\n",
        "#     run_prediction,\n",
        "# )\n",
        "# from prompts import single_shot_disease_only_prompt,with_reasons_prompt,compare_others_prompt,self_refinement_prompt\n",
        "# type=\"with_reasons\"\n",
        "# prompt=with_reasons_prompt\n",
        "# type=\"single_shot\"\n",
        "# prompt=single_shot_disease_only_prompt\n",
        "# # type=\"open_ended\"\n",
        "# # # prompt=open_ended__top4_prompt#\n",
        "# run_prediction(df,prompt,departments,models=models,type=type,skip=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfEQK4P93wCC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import os\n",
        "# import json\n",
        "# from src.utils import evaluate_department_results\n",
        "# types=[\"single_shot\",\"with_reasons\",\"check_others_input\"]\n",
        "\n",
        "# for type in types:\n",
        "#     folder=os.path.join(\"results\",type)\n",
        "#     print(\"type is\",type)\n",
        "#     all_files=os.listdir(folder)\n",
        "#     all_results={}\n",
        "#     for file in all_files:\n",
        "#         department_name=file.split(\"_\")[0]\n",
        "#         print(department_name)\n",
        "#         if type in file:\n",
        "#             file_path=os.path.join(folder,file)\n",
        "#             department_name=file.split(\"_\")[0]\n",
        "#             with open(file_path, \"r\") as file:\n",
        "#                 data = json.load(file)\n",
        "#                 results=evaluate_department_results(data)\n",
        "#             all_results[department_name]=results\n",
        "\n",
        "#     with open(f\"results/analysis/{type}.json\", \"w\") as outfile:\n",
        "#         json.dump(all_results, outfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiKwIDpK37Bj",
        "outputId": "8e9044c9-15fc-4632-d5e7-7a5a8dbfb103"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "!sudo apt update\n",
        "!sudo apt install -y pciutils\n",
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLWMXzBX5N18"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "def run_ollama_serve():\n",
        "  subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "thread = threading.Thread(target=run_ollama_serve)\n",
        "thread.start()\n",
        "time.sleep(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B_eVzLo5Piq",
        "outputId": "80b7d138-100f-4e0f-da13-0af8109ba87e"
      },
      "outputs": [],
      "source": [
        "!ollama pull llama3.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4FDqcIA3wCD"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate\n",
        "from langchain_ollama.llms import OllamaLLM\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMzSUAou3wCE"
      },
      "outputs": [],
      "source": [
        "required_fields=[ \"Patient basic information\",\n",
        "                 \"Chief complaint\",\n",
        "                 \"Medical history\",\n",
        "                 \"Physical examination\",\n",
        "                 \"Laboratory examination\",\n",
        "                 \"Imageological examination\",\n",
        "                 \"Auxillary examination\",\n",
        "                 \"Pathological examination\"\n",
        "\n",
        "]\n",
        "departments=[\"nephrology department\",\n",
        "            \"gynecology department\",\n",
        "            \"endocrinology department\",\n",
        "            \"neurology department\",\n",
        "             \"pediatrics department\",\n",
        "             \"cardiac surgical department\",\n",
        "             \"gastrointestinal surgical department\",\n",
        "             \"respiratory medicine department\",\n",
        "             \"gastroenterology department\",\n",
        "             \"urinary surgical department\",\n",
        "             \"hepatobiliary and pancreas surgical department\",\n",
        "             \"hematology department\"\n",
        "            ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFjQUYMo3wCF"
      },
      "outputs": [],
      "source": [
        "def get_diagnosis_by_other_models_by_id(id,department_results,models):\n",
        "    all_diagnosis=[]\n",
        "    for model in models:\n",
        "        diagnosis=department_results[id][\"predictions\"][model]\n",
        "        diagnosis= diagnosis.replace(\"\\n\", \"\")\n",
        "        diagnosis= diagnosis.replace(\"```json\", \"\")\n",
        "        diagnosis= diagnosis.replace(\"```\", \"\")\n",
        "        all_diagnosis.append(diagnosis)\n",
        "    return all_diagnosis\n",
        "\n",
        "def compare_others_ollama(prompt,medical_history, modelname, diseases, department,doctor_diagnosis=[]):\n",
        "    model = OllamaLLM(model=modelname,temperature=0.1,num_predict=1500,num_ctx=4096)#1500\n",
        "\n",
        "    system_template = prompt\n",
        "\n",
        "    system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
        "    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt])\n",
        "    chain = chat_prompt | model\n",
        "    if len(doctor_diagnosis)==1:\n",
        "        results=chain.invoke({\"department\": department,\n",
        "                            \"diseases\": diseases,\n",
        "                            \"medical_history\":json.dumps(medical_history),\n",
        "                            \"diagnosis\":doctor_diagnosis[0]})\n",
        "        return results\n",
        "    elif len(doctor_diagnosis)==2:\n",
        "        results=chain.invoke({\"department\": department,\n",
        "                            \"diseases\": diseases,\n",
        "                            \"medical_history\":json.dumps(medical_history),\n",
        "                            \"doctor_1_diagnosis\":doctor_diagnosis[0],\n",
        "                            \"doctor_2_diagnosis\":doctor_diagnosis[1]})\n",
        "        return results\n",
        "    elif len(doctor_diagnosis)==3:\n",
        "        results=chain.invoke({\"department\": department,\n",
        "                            \"diseases\": diseases,\n",
        "                            \"medical_history\":json.dumps(medical_history),\n",
        "                            \"doctor_1_diagnosis\":doctor_diagnosis[0],\n",
        "                            \"doctor_2_diagnosis\":doctor_diagnosis[1],\n",
        "                            \"doctor_3_diagnosis\":doctor_diagnosis[2]})\n",
        "        return results\n",
        "\n",
        "\n",
        "\n",
        "def compare_others_gpt(prompt,medical_history, model, diseases, department,doctor_diagnosis=[]):\n",
        "    chat = ChatOpenAI(model_name=model, temperature=0.1,max_tokens=1500)\n",
        "    system_template = prompt\n",
        "    system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
        "\n",
        "    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt])\n",
        "\n",
        "    # Format the messages\n",
        "    messages = chat_prompt.format_prompt(\n",
        "        department=department,\n",
        "        diseases=diseases,\n",
        "        medical_history=json.dumps(medical_history),\n",
        "        doctor_1_diagnosis=doctor_diagnosis[0],\n",
        "        doctor_2_diagnosis=doctor_diagnosis[1],\n",
        "        doctor_3_diagnosis=doctor_diagnosis[2],\n",
        "\n",
        "    ).to_messages()\n",
        "    response = chat(messages)\n",
        "    return response.content\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQmdF6QT3wCG"
      },
      "source": [
        "### Check others including mine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jC94dh83wCG"
      },
      "outputs": [],
      "source": [
        "\n",
        "all_models= [\"gpt-4o\",\"llama3.1\",\"gemma2\"]\n",
        "all_models_to_check=[\"gpt-4o\",\"llama3.1\",\"gemma2\"]\n",
        "type=\"check_others_input\"\n",
        "prompt_type=compare_others_prompt\n",
        "for department in departments:\n",
        "    print(department)\n",
        "    results={}\n",
        "    with open(f\"results4/with_reasons/{department}_with_reasons.json\", \"r\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    department_results=data\n",
        "    ids=list(department_results.keys())\n",
        "    print(ids)\n",
        "    for case_id in ids:\n",
        "        print(case_id)\n",
        "        case_details={}\n",
        "        principal_diagnosis,differential_diagnosis,filtered_clinical_case_dict=select_case_components_based_on_id(df,int(case_id),required_fields)\n",
        "        doctor_diagnosis=get_diagnosis_by_other_models_by_id(case_id,department_results,all_models)\n",
        "        case_details[\"original\"]={\"main-diagnosis\":principal_diagnosis,\"differential_diagnosis\":differential_diagnosis}\n",
        "        case_details[\"predictions\"]={}\n",
        "        for model in all_models_to_check:\n",
        "            if \"gpt\" in model:\n",
        "                output=compare_others_gpt(prompt_type,filtered_clinical_case_dict,model,differential_diagnosis,department,doctor_diagnosis)\n",
        "            else:\n",
        "                output=compare_others_ollama(prompt_type,filtered_clinical_case_dict,model,differential_diagnosis,department,doctor_diagnosis)\n",
        "            case_details[\"predictions\"][model]=output\n",
        "        results[str(case_id)]=case_details\n",
        "\n",
        "    with open(f\"results/{type}/{department}_{type}.json\", \"w\") as outfile:\n",
        "        json.dump(results, outfile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqMYjqwl3wCH"
      },
      "source": [
        "### Self refinement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6Ih2EZM3wCH",
        "outputId": "edb50f21-a681-409e-ab54-71e496eda4d5"
      },
      "outputs": [],
      "source": [
        "all_models= [\"llama3.1\"]\n",
        "all_models_to_check=[\"llama3.1\"]\n",
        "type=\"self_refinement\"\n",
        "prompt_type=self_refinement_prompt\n",
        "for department in departments:\n",
        "    print(department)\n",
        "    results={}\n",
        "    with open(f\"results4/with_reasons/{department}_with_reasons.json\", \"r\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    department_results=data\n",
        "    ids=list(department_results.keys())\n",
        "    print(ids)\n",
        "    for case_id in ids:\n",
        "        print(case_id)\n",
        "        case_details={}\n",
        "        principal_diagnosis,differential_diagnosis,filtered_clinical_case_dict=select_case_components_based_on_id(df,int(case_id),required_fields)\n",
        "        doctor_diagnosis=get_diagnosis_by_other_models_by_id(case_id,department_results,all_models)\n",
        "        case_details[\"original\"]={\"main-diagnosis\":principal_diagnosis,\"differential_diagnosis\":differential_diagnosis}\n",
        "        case_details[\"predictions\"]={}\n",
        "        for i,model in enumerate(all_models_to_check):\n",
        "            doctor_diagnosis=[doctor_diagnosis[i]]\n",
        "            if \"gpt\" in model:\n",
        "                output=compare_others_gpt(prompt_type,filtered_clinical_case_dict,model,differential_diagnosis,department,doctor_diagnosis)\n",
        "            else:\n",
        "                output=compare_others_ollama(prompt_type,filtered_clinical_case_dict,model,differential_diagnosis,department,doctor_diagnosis)\n",
        "            case_details[\"predictions\"][model]=output\n",
        "        results[str(case_id)]=case_details\n",
        "    path = f\"results5/{type}/{model}/{department}_{type}.json\"\n",
        "    folder_path = os.path.dirname(path)\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "    with open(path, \"w\") as outfile:\n",
        "      json.dump(results, outfile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT58HWpv3wCH"
      },
      "source": [
        "### Check others without mine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cb6ANtx3wCI"
      },
      "outputs": [],
      "source": [
        "all_models= [\"gpt-4o\",\"llama3.1\",\"gemma2\"]\n",
        "all_models_to_check=[\"gpt-4o\",\"llama3.1\",\"gemma2\"]\n",
        "type=\"check_others_input_without_mine\"\n",
        "prompt_type=compare_others_prompt_without_mine\n",
        "for department in departments:\n",
        "    print(department)\n",
        "    results={}\n",
        "    with open(f\"results4/with_reasons/{department}_with_reasons.json\", \"r\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    department_results=data\n",
        "    ids=list(department_results.keys())\n",
        "    print(ids)\n",
        "    for case_id in ids:\n",
        "        print(case_id)\n",
        "        case_details={}\n",
        "        principal_diagnosis,differential_diagnosis,filtered_clinical_case_dict=select_case_components_based_on_id(df,int(case_id),required_fields)\n",
        "        doctor_diagnosis=get_diagnosis_by_other_models_by_id(case_id,department_results,all_models)\n",
        "        case_details[\"original\"]={\"main-diagnosis\":principal_diagnosis,\"differential_diagnosis\":differential_diagnosis}\n",
        "        case_details[\"predictions\"]={}\n",
        "        for i,model in enumerate(all_models_to_check):\n",
        "            doctor_diagnosis1=doctor_diagnosis[:]\n",
        "            if model==\"gpt-4o\":\n",
        "              continue\n",
        "            del doctor_diagnosis1[i]\n",
        "\n",
        "            if \"gpt\" in model:\n",
        "                output=compare_others_gpt(prompt_type,filtered_clinical_case_dict,model,differential_diagnosis,department,doctor_diagnosis1)\n",
        "            else:\n",
        "                output=compare_others_ollama(prompt_type,filtered_clinical_case_dict,model,differential_diagnosis,department,doctor_diagnosis1)\n",
        "            case_details[\"predictions\"][model]=output\n",
        "        results[str(case_id)]=case_details\n",
        "\n",
        "    path = f\"results5/{type}/{model}/{department}_{type}.json\"\n",
        "    folder_path = os.path.dirname(path)\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "    with open(path, \"w\") as outfile:\n",
        "      json.dump(results, outfile)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
